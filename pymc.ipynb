{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = \"retina\"\n",
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams[\"savefig.dpi\"] = 100\n",
    "rcParams[\"figure.dpi\"] = 100\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pymc3 as pm\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "config = tf.ConfigProto(intra_op_parallelism_threads=4, inter_op_parallelism_threads=4)\n",
    "session = tf.InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/pymc-devs/pymc3/issues/804\n",
    "# https://docs.pymc.io/advanced_theano.html#writing-custom-theano-ops\n",
    "# http://deeplearning.net/software/theano/extending/extending_theano.html\n",
    "\n",
    "import theano\n",
    "\n",
    "def _to_tensor_type(shape):\n",
    "    return theano.tensor.TensorType(dtype=\"float64\",\n",
    "                                    broadcastable=[False]*len(shape))\n",
    "\n",
    "\n",
    "class TensorFlowOp(theano.Op):\n",
    "    \"\"\"A custom Theano Op uses TensorFlow as the computation engine\n",
    "    \n",
    "    Args:\n",
    "        target (Tensor): The TensorFlow tensor defining the output of\n",
    "            this operation\n",
    "        parameters (list(Tensor)): A list of TensorFlow tensors that\n",
    "            are inputs to this operation\n",
    "        feed_dict (Optional(dict)): A \"feed_dict\" that is provided to\n",
    "            the TensorFlow session when the operation is executed\n",
    "        session (Optional): A TensorFlow session that can be used to\n",
    "            evaluate the operation\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, target, parameters, feed_dict=None, session=None):\n",
    "        self.parameters = parameters\n",
    "        self._feed_dict = dict() if feed_dict is None else feed_dict\n",
    "        self._session = session\n",
    "        self.target = target\n",
    "        self.init_shapes()\n",
    "        \n",
    "        self.itypes = [_to_tensor_type(shape) for shape in self.shapes]\n",
    "        self.otypes = [_to_tensor_type(self.output_shape)]\n",
    "        \n",
    "        self._grad_op = _TensorFlowGradOp(self)\n",
    "    \n",
    "    @property\n",
    "    def session(self):\n",
    "        if self._session is None:\n",
    "            self._session = tf.get_default_session()\n",
    "        return self._session\n",
    "\n",
    "    def init_shapes(self):\n",
    "        \"\"\"\n",
    "        Execute the operation once to determine the shapes of the tensors\n",
    "        \"\"\"\n",
    "        self.grad_target = tf.gradients(self.target, self.parameters)\n",
    "        in_values, out_value = self.session.run(\n",
    "            [self.parameters, self.target], feed_dict=self._feed_dict)\n",
    "        self.shapes = [np.shape(v) for v in in_values]\n",
    "        self.output_shape = np.shape(out_value)\n",
    "\n",
    "    def infer_shape(self, node, shapes):\n",
    "        return self.output_shape,\n",
    "\n",
    "    def perform(self, node, inputs, outputs):\n",
    "        \"\"\"Execute the operation using TensorFlow\"\"\"\n",
    "        feed_dict = dict(zip(self.parameters, inputs), **self._feed_dict)\n",
    "        outputs[0][0] = np.array(self.session.run(self.target, feed_dict=feed_dict))\n",
    "\n",
    "    def grad(self, inputs, gradients):\n",
    "        return self._grad_op(*(inputs + gradients))\n",
    "    \n",
    "\n",
    "class _TensorFlowGradOp(theano.Op):\n",
    "    \"\"\"A custom Theano Op defining the gradient of a TensorFlowOp\n",
    "    \n",
    "    Args:\n",
    "        base_op (TensorFlowOp): The original Op\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, base_op):\n",
    "        self.base_op = base_op\n",
    "        self.dy = tf.placeholder(tf.float64, base_op.output_shape)\n",
    "        self.grad_target = tf.gradients(base_op.target,\n",
    "                                        base_op.parameters,\n",
    "                                        grad_ys=self.dy)\n",
    "        types = [_to_tensor_type(shape) for shape in base_op.shapes]\n",
    "        self.itypes = types + [_to_tensor_type(base_op.output_shape)]\n",
    "        self.otypes = types\n",
    "\n",
    "    def infer_shape(self, node, shapes):\n",
    "        return self.base_op.shapes\n",
    "\n",
    "    def perform(self, node, inputs, outputs):\n",
    "        feed_dict = dict(zip(self.base_op.parameters, inputs[:-1]),\n",
    "                         **self.base_op._feed_dict)\n",
    "        feed_dict[self.dy] = inputs[-1]\n",
    "        result = self.base_op.session.run(self.grad_target, feed_dict=feed_dict)\n",
    "        for i, r in enumerate(result):\n",
    "            outputs[i][0] = np.array(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# np.random.seed(1234)\n",
    "\n",
    "# m = tf.Variable(0.5, dtype=tf.float64)\n",
    "# b = tf.Variable(-0.1, dtype=tf.float64)\n",
    "# log_s2 = tf.Variable(2*np.log(0.1), dtype=tf.float64)\n",
    "# session.run(tf.global_variables_initializer())\n",
    "\n",
    "# N = 10\n",
    "# x = tf.constant(np.random.uniform(-3, 3, N))\n",
    "# mu = m * x + b\n",
    "# y_obs = mu.eval() + 0.5 * np.random.randn(N)\n",
    "\n",
    "# log_prob = -0.5 * tf.reduce_sum(tf.square(y_obs - mu)) / tf.exp(log_s2)\n",
    "# log_prob -= 0.5 * N * log_s2\n",
    "\n",
    "# log_prob_op = TensorFlowOp(log_prob, [m, b, log_s2])\n",
    "\n",
    "# with pm.Model() as model:\n",
    "#     m_var = pm.Uniform(\"m\", lower=-5, upper=5)\n",
    "#     b_var = pm.Uniform(\"b\", lower=-5, upper=5)\n",
    "#     log_s2_var = pm.Uniform(\"log_s2\", lower=-5, upper=5)\n",
    "#     pm.Potential(\"log_prob\", log_prob_op(m_var, b_var, log_s2_var))\n",
    "\n",
    "#     trace = pm.sample(cores=1, tune=2000, draws=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(x.eval(), y_obs, \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import corner\n",
    "# samples = np.vstack([trace[k] for k in [\"m\", \"b\", \"log_s2\"]]).T\n",
    "# corner.corner(samples);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exoplanet import kepler, transit, interp\n",
    "\n",
    "# Typical Gaia density:\n",
    "log_density_prior = -1.45, 0.35\n",
    "\n",
    "dt = 1.0 / 24.0 / 60.0  # 1 minute cadence\n",
    "# dt = 0.5 / 24.0  # 30 minute cadence\n",
    "t = np.arange(0, 27.0, dt)\n",
    "print(len(t))\n",
    "\n",
    "T = tf.float64\n",
    "np.random.seed(42)\n",
    "\n",
    "G_grav = 2945.462538537765\n",
    "factor = (G_grav / (3 * np.pi)) ** (1./3)\n",
    "\n",
    "t_tensor = tf.constant(t, dtype=T)\n",
    "\n",
    "# Star\n",
    "flux = tf.Variable(0.0, dtype=T)\n",
    "q = tf.Variable(0.5 + np.zeros(2), dtype=T)\n",
    "log_rho_star = tf.Variable(log_density_prior[0], dtype=T)\n",
    "rho_star = tf.exp(log_rho_star)\n",
    "\n",
    "# Build the limb darkening model\n",
    "q1 = q[0]\n",
    "q2 = q[1]\n",
    "c1 = 2.0 * tf.sqrt(q1) * q2\n",
    "c2 = tf.sqrt(q1) * (1.0 - 2.0 * q2)\n",
    "ld = transit.QuadraticLimbDarkening(c1, c2)\n",
    "\n",
    "# Set up the planet parameters\n",
    "n_pl = 2\n",
    "p_samp = np.random.uniform(30.0, 60.0, 1)\n",
    "t0_samp = np.random.uniform(t.min(), t.max(), 1)\n",
    "r_samp = np.random.uniform(0.04, 0.1, 1)\n",
    "b_samp = np.random.uniform(0, 1, 1)\n",
    "e_samp = np.random.uniform(0, 0.5, 1)\n",
    "omega_samp = np.random.randn(1, 2)\n",
    "if n_pl > 1:\n",
    "    p_samp = np.append(p_samp,\n",
    "                       np.random.uniform(3, (t.max() - t.min())/5, n_pl-1))\n",
    "    t0_samp = np.append(t0_samp, p_samp[1:] * np.random.rand(n_pl-1))\n",
    "    r_samp = np.append(r_samp, np.random.uniform(0.04, 0.08, n_pl-1))\n",
    "    b_samp = np.append(b_samp, np.random.uniform(0, 1, n_pl-1))\n",
    "    e_samp = np.append(e_samp, np.random.uniform(0, 0.5, n_pl-1))\n",
    "    omega_samp = np.concatenate((omega_samp, np.random.randn(n_pl-1, 2)), axis=0)\n",
    "\n",
    "y_err = np.random.uniform(0.3, 0.9, len(t))\n",
    "noise = y_err * np.random.randn(len(t))\n",
    "    \n",
    "log_period = tf.Variable(np.log(p_samp), dtype=T)\n",
    "log_ror = tf.Variable(np.log(r_samp), dtype=T)\n",
    "t0 = tf.Variable(t0_samp, dtype=T)\n",
    "b = tf.Variable(b_samp, dtype=T)\n",
    "e = tf.Variable(e_samp, dtype=T)\n",
    "omega_vec = tf.Variable(omega_samp / np.sqrt(np.sum(omega_samp**2, axis=-1)), dtype=T)\n",
    "\n",
    "omega_norm = tf.reduce_sum(tf.square(omega_vec), axis=-1)\n",
    "omega = omega_vec / tf.expand_dims(tf.sqrt(omega_norm), -1)\n",
    "\n",
    "period = tf.exp(log_period)\n",
    "ror = tf.exp(log_ror)\n",
    "\n",
    "# Compute the orbit model\n",
    "a = factor * period**(2./3) * rho_star**(1./3)\n",
    "cosi = tf.abs(b) / a\n",
    "incl = tf.acos(cosi)\n",
    "\n",
    "sin_omega = omega_vec[:, 0]\n",
    "cos_omega = omega_vec[:, 1]\n",
    "omega = tf.atan2(sin_omega, cos_omega)\n",
    "\n",
    "\n",
    "coords = a[None, :, None] * kepler.sky_position(\n",
    "    period[:, None],\n",
    "    t0[:, None],\n",
    "    e[:, None],\n",
    "    omega[:, None],\n",
    "    incl[:, None],\n",
    "    t_tensor[None, :], tol=1e-5)\n",
    "\n",
    "d = tf.sqrt(tf.reduce_sum(tf.square(coords[:2]), axis=0))\n",
    "delta = transit.transit_depth(ld, d, ror[:, None]+tf.zeros_like(d), direction=coords[2], n_integrate=100)\n",
    "light_curve = flux - 1e3*tf.reduce_sum(delta, axis=0)\n",
    "\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "y_true = light_curve.eval()\n",
    "y_obs = y_true + noise\n",
    "\n",
    "y_tensor = tf.constant(y_obs, dtype=T)\n",
    "y_err_tensor = tf.constant(y_err, dtype=T)\n",
    "\n",
    "logprob = -0.5 * tf.reduce_sum(tf.square((y_tensor - light_curve) / y_err_tensor))\n",
    "\n",
    "# Omega prior\n",
    "# logprob -= 0.5 * tf.reduce_sum(omega_norm)\n",
    "\n",
    "# Density prior\n",
    "logprob -= 0.5 * tf.square((log_rho_star - log_density_prior[0]) / log_density_prior[1])\n",
    "\n",
    "# Beta prior\n",
    "alpha = 0.867\n",
    "beta = 3.03\n",
    "logprob += 2*tf.reduce_sum((alpha-1)*tf.log(e) + (beta-1)*tf.log(1-e))\n",
    "\n",
    "params = [flux, q, log_rho_star, log_period, log_ror, t0, b, e, omega_vec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(t, y_obs)\n",
    "plt.plot(t, light_curve.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_prob_op = TensorFlowOp(logprob, params)\n",
    "\n",
    "with pm.Model() as model:\n",
    "    flux_var = pm.Uniform(\"flux\", lower=-5, upper=5)\n",
    "    q_var = pm.Uniform(\"q\", shape=(2,), lower=0, upper=1)\n",
    "    log_rho_star_var = pm.Uniform(\"logrhostar\", lower=-5, upper=5)\n",
    "    log_period_var = pm.Uniform(\"logperiod\", shape=(n_pl,), lower=np.log(3), upper=np.log(5000))\n",
    "    t0_var = pm.Uniform(\"t0\", shape=(n_pl,), lower=0, upper=t.max()-t.min())\n",
    "    log_ror_var = pm.Uniform(\"logror\", shape=(n_pl,), lower=np.log(0.01), upper=np.log(0.2))\n",
    "    b_var = pm.Uniform(\"b\", shape=(n_pl,), lower=0, upper=2)\n",
    "    e_var = pm.Uniform(\"e\", shape=(n_pl,), lower=0, upper=1)\n",
    "    omega_var = pm.Normal(\"omega\", shape=(n_pl, 2))\n",
    "\n",
    "    start = {\n",
    "        \"flux\": flux.eval(),\n",
    "        \"q\": q.eval(),\n",
    "        \"logrhostar\": log_rho_star.eval(),\n",
    "        \"logperiod\": log_period.eval(),\n",
    "        \"t0\": t0.eval(),\n",
    "        \"logror\": log_ror.eval(),\n",
    "        \"b\": b.eval(),\n",
    "        \"e\": e.eval(),\n",
    "        \"omega\": omega_vec.eval(),\n",
    "    }\n",
    "    \n",
    "    lp = log_prob_op(flux_var, q_var, log_rho_star_var, log_period_var,\n",
    "                     log_ror_var, t0_var, b_var, e_var, omega_var)\n",
    "    pm.Potential(\"log_prob\", lp)\n",
    "\n",
    "    map_val = pm.find_MAP(start=start)\n",
    "    map_val = pm.find_MAP(start=start)\n",
    "    map_val = pm.find_MAP(start=start)\n",
    "    trace = pm.sample(cores=1, chains=1, tune=1000, draws=1000, start=map_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(trace);\n",
    "plt.savefig(\"traces.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.exp(trace[\"logperiod\"][:, 0]), 50, color=\"k\")\n",
    "plt.axvline(p_samp[0])\n",
    "plt.axvline(t.max() - t.min());\n",
    "plt.savefig(\"period.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = np.percentile(np.exp(trace[\"logperiod\"][:, 0]), [16, 50, 84])\n",
    "print(q[1], np.diff(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!open ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.exp(trace[\"logperiod\"][:, 0]), 50, color=\"k\")\n",
    "plt.axvline(p_samp[0])\n",
    "plt.axvline(t.max() - t.min())\n",
    "plt.xlabel(\"period [days]\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.exp(trace[\"logperiod\"][:, 0]), 50, color=\"k\")\n",
    "plt.axvline(p_samp[0])\n",
    "plt.axvline(t.max() - t.min());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
