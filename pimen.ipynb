{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = \"retina\"\n",
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams[\"savefig.dpi\"] = 100\n",
    "rcParams[\"figure.dpi\"] = 100\n",
    "rcParams[\"font.size\"] = 20\n",
    "\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy.stats import BoxLeastSquares\n",
    "\n",
    "import pymc3 as pm\n",
    "import theano.tensor as tt\n",
    "from exoplanet.theano_ops import kepler, starry, celerite\n",
    "from exoplanet.distributions import Angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pimen_data():\n",
    "    # Download the RV dataset from the Exoplanet Archive:\n",
    "    url = \"https://exoplanetarchive.ipac.caltech.edu/data/ExoData/0026/0026394/data/UID_0026394_RVC_001.tbl\"\n",
    "    r = requests.get(url)\n",
    "    if r.status_code != requests.codes.ok:\n",
    "        r.raise_for_status()\n",
    "    data = np.array([l.split() for l in r.text.splitlines()\n",
    "                     if not l.startswith(\"\\\\\") and not l.startswith(\"|\")],\n",
    "                    dtype=float)\n",
    "    t, rv, rv_err = data.T\n",
    "    t -= np.mean(t)\n",
    "\n",
    "    # Plot the observations \"folded\" on the published period:\n",
    "    lit_period = 2091.2\n",
    "    \n",
    "    plt.plot()\n",
    "    plt.errorbar(t, rv, yerr=rv_err, fmt=\".k\", capsize=0)\n",
    "    # plt.xlim(0, 1)\n",
    "    plt.ylim(-110, 110)\n",
    "    plt.ylabel(\"radial velocity [m/s]\")\n",
    "    plt.xlabel(\"phase\");\n",
    "    \n",
    "    tpf_url = \"https://archive.stsci.edu/hlsps/tess-data-alerts/hlsp_tess-data-alerts_tess_phot_00261136679-s01_tess_v1_tp.fits\"\n",
    "    with fits.open(tpf_url) as hdus:\n",
    "        tpf = hdus[1].data\n",
    "        tpf_hdr = hdus[1].header\n",
    "        tpf_mask = hdus[2].data\n",
    "        \n",
    "    lc_url = \"https://archive.stsci.edu/hlsps/tess-data-alerts/hlsp_tess-data-alerts_tess_phot_00261136679-s01_tess_v1_lc.fits\"\n",
    "    with fits.open(lc_url) as hdus:\n",
    "        lc = hdus[1].data\n",
    "        lc_hdr = hdus[1].header\n",
    "        \n",
    "    return (t, rv, rv_err), (tpf, tpf_hdr, tpf_mask), (lc, lc_hdr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(t, rv, rv_err), (tpf, tpf_hdr, tpf_mask), (lc, lc_hdr) = get_pimen_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = (lc[\"QUALITY\"] == 0) & np.isfinite(lc[\"PDCSAP_FLUX\"]) & np.isfinite(lc[\"TIME\"])\n",
    "\n",
    "x = lc[\"TIME\"][m]\n",
    "y = lc[\"PDCSAP_FLUX\"][m]\n",
    "mu = np.median(y)\n",
    "y = y / mu - 1\n",
    "yerr = lc[\"PDCSAP_FLUX_ERR\"][m] / mu\n",
    "\n",
    "# Initial PLD model + sigma clipping\n",
    "X_pld = np.reshape(tpf[\"FLUX\"][:, tpf_mask == 267], (len(tpf), -1))[m, :] / lc[\"PDCSAP_FLUX\"][m, None]\n",
    "X_pld = np.concatenate((X_pld, np.ones((len(X_pld), 1))), axis=1)\n",
    "\n",
    "# Sigma clipping\n",
    "m_new = np.ones(len(X_pld), dtype=bool)\n",
    "for i in range(10):\n",
    "    w_pld = np.linalg.solve(np.dot(X_pld[m_new].T, X_pld[m_new]),\n",
    "                            np.dot(X_pld[m_new].T, y[m_new]))\n",
    "    pld_mod = np.dot(X_pld, w_pld)\n",
    "    resid = np.abs(y - pld_mod)\n",
    "    sigma = np.sqrt(np.mean(resid**2))\n",
    "    m_update = resid < 3 * sigma\n",
    "    if m_update.sum() == m_new.sum():\n",
    "        m_new = m_update\n",
    "        break\n",
    "    m_new = m_update\n",
    "    \n",
    "x = np.ascontiguousarray(x[m_new], dtype=np.float64)\n",
    "x -= np.min(x)\n",
    "y = np.ascontiguousarray(y[m_new], dtype=np.float64)\n",
    "yerr = np.ascontiguousarray(yerr[m_new], dtype=np.float64)\n",
    "X_pld = np.ascontiguousarray(X_pld[m_new], dtype=np.float64)\n",
    "pld_mod = np.ascontiguousarray(pld_mod[m_new], dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bls_model = BoxLeastSquares(x, y - pld_mod, yerr)\n",
    "periods = np.exp(np.linspace(np.log(1), np.log(15), 2000))\n",
    "results = bls_model.power(periods, 0.05)\n",
    "\n",
    "ind = np.argmax(results.power)\n",
    "period_guess = results.period[ind]\n",
    "t0_guess = results.transit_time[ind]\n",
    "depth_guess = results.depth[ind]\n",
    "\n",
    "plt.plot(results.period, results.power, \"k\")\n",
    "plt.axvline(period_guess)\n",
    "plt.ylabel(\"BLS power\")\n",
    "plt.xlabel(\"period\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(10, 6))\n",
    "\n",
    "ax = axes[0]\n",
    "ax.plot(x, y - pld_mod, \".k\")\n",
    "\n",
    "x_fold = (x - t0_guess + 0.5*period_guess) % period_guess - 0.5*period_guess\n",
    "bins = np.linspace(-0.5*period_guess, 0.5*period_guess, 200)\n",
    "denom, _ = np.histogram(x_fold, bins)\n",
    "num, _ = np.histogram(x_fold, bins, weights=y - pld_mod)\n",
    "\n",
    "ax = axes[1]\n",
    "ax.plot(x_fold, y - pld_mod, \".k\", alpha=0.3)\n",
    "ax.plot(0.5*(bins[1:] + bins[:-1]), num / denom);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_near = np.abs(x_fold) < 0.5\n",
    "x = np.ascontiguousarray(x[m_near], dtype=np.float64)\n",
    "y = np.ascontiguousarray(y[m_near], dtype=np.float64)\n",
    "yerr = np.ascontiguousarray(yerr[m_near], dtype=np.float64)\n",
    "X_pld = np.ascontiguousarray(X_pld[m_near], dtype=np.float64)\n",
    "pld_mod = np.ascontiguousarray(pld_mod[m_near], dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_fit = (y - pld_mod) * 1e3\n",
    "yerr_fit = yerr * 1e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = 3\n",
    "oversample = oversample + oversample % 2\n",
    "dt = 2.0 / 60.0 / 60.0 / 24.0 * np.linspace(-0.5, 0.5, oversample)\n",
    "stencil = np.ones(oversample)\n",
    "stencil[1:-1:2] = 4\n",
    "stencil[2:-1:2] = 2\n",
    "stencil /= np.sum(stencil)\n",
    "tgrid = x[:, None] + dt[None, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_cm3_gm1_sm2 = 6.674e-8\n",
    "G_cm3_gm1_dm2 = G_cm3_gm1_sm2 * (60.0 * 60.0 * 24.0)**2\n",
    "\n",
    "with pm.Model() as model:\n",
    "    \n",
    "    # Limb darkening\n",
    "    q = pm.Uniform(\"q\", lower=0.0, upper=1.0, shape=(2,),\n",
    "                   testval=np.array([0.5, 0.5]))\n",
    "    u = tt.stack([\n",
    "        2.0 * tt.sqrt(q[0]) * q[1],\n",
    "        tt.sqrt(q[0]) * (1.0 - 2.0 * q[1]),\n",
    "    ])\n",
    "    pm.Deterministic(\"u\", u)\n",
    "\n",
    "    # Stellar density\n",
    "    rho = pm.Normal(\"rho\", mu=1.148, sd=0.065, testval=1.148)\n",
    "\n",
    "    # Mean stellar flux\n",
    "    mean = pm.Normal(\"mean\", mu=0.0, sd=10.0, testval=0.0)\n",
    "    \n",
    "    # Orbit parameters\n",
    "    logporb = pm.Normal(\"logporb\",\n",
    "                        mu=np.log(period_guess),\n",
    "                        sd=1.0,\n",
    "                        testval=np.log(period_guess))\n",
    "    t0 = pm.Uniform(\"t0\", lower=t0_guess-0.1, upper=t0_guess+0.1, testval=t0_guess)\n",
    "    b = pm.Uniform(\"b\", lower=0.0, upper=2.0, testval=0.6)\n",
    "    logr = pm.Uniform(\"logr\", lower=np.log(0.01), upper=np.log(0.1),\n",
    "                          testval=0.5*np.log(depth_guess))\n",
    "    ecc = pm.Beta(\"ecc\", alpha=0.867, beta=3.03, testval=0.01)\n",
    "    w = Angle(\"w\", testval=0.0)\n",
    "    \n",
    "    # Derived orbital parameters\n",
    "    a = (G_cm3_gm1_dm2 * rho * tt.exp(2*logporb) / (3*np.pi))**(1./3)\n",
    "    pm.Deterministic(\"a\", a)\n",
    "    porb = pm.Deterministic(\"porb\", tt.exp(logporb))\n",
    "    ror = pm.Deterministic(\"ror\", tt.exp(logr))\n",
    "    incl = pm.Deterministic(\"incl\", tt.arccos(b / a))\n",
    "#     w = pm.Deterministic(\"w\", tt.arctan2(wvec[1], wvec[0]))\n",
    "    \n",
    "    # Solve Kepler's equation and get the sky coordinates\n",
    "    coords = a * kepler.get_sky_coords(porb, t0, ecc, w, incl, tgrid)\n",
    "    pm.Deterministic(\"coords\", coords)\n",
    "    rsky = tt.sqrt(tt.sum(coords[:2]**2, axis=0))\n",
    "    rsky = tt.switch(coords[2] > 0, rsky, 100 * tt.ones_like(rsky))\n",
    "\n",
    "    # Compute the transit model\n",
    "    transit = starry.light_curve(u, rsky, ror + tt.zeros_like(rsky))\n",
    "    transit = (tt.sum(stencil[None, :] * transit, axis=1) - 1.0) * 1e3 - mean\n",
    "    pm.Deterministic(\"transit\", transit)\n",
    "        \n",
    "    # Likelihood\n",
    "    logs2 = pm.Uniform(\"logs2\", lower=-20, upper=0, testval=2*np.log(np.median(yerr_fit)))\n",
    "#     pm.Normal(\"obs\", mu=transit, sd=tt.sqrt(yerr**2 + tt.exp(logs2)), observed=y_fit)\n",
    "    \n",
    "    resid = y_fit - transit\n",
    "    logS0 = pm.Uniform(\"logS0\", lower=-20, upper=0, testval=np.log(np.var(y_fit)))\n",
    "    logw0 = pm.Uniform(\"logw0\", lower=np.log(2*np.pi/30.0), upper=np.log(2*np.pi/1.0),\n",
    "                       testval=np.log(2*np.pi/5.0))\n",
    "#     logQ = pm.Uniform(\"logQ\", lower=-0.5*np.log(2), upper=5.0, testval=1.0)\n",
    "    kernel = celerite.terms.SHOTerm(S0=tt.exp(logS0), w0=tt.exp(logw0), Q=1/np.sqrt(2))\n",
    "    \n",
    "    gp = celerite.GP(kernel, x, yerr**2 + tt.exp(logs2), J=2)\n",
    "    pm.Potential(\"obs\", gp.log_likelihood(resid))\n",
    "    \n",
    "    pm.Deterministic(\"gp\", gp.predict())\n",
    "    \n",
    "    soln = pm.find_MAP(start=model.test_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, y_fit, \".k\")\n",
    "plt.plot(x, soln[\"transit\"])\n",
    "plt.plot(x, soln[\"gp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_start = 100\n",
    "n_burn = 100\n",
    "n_tune = 1000\n",
    "n_window = n_start * 2 ** np.arange(np.floor(np.log2((n_tune - n_burn) / n_start)))\n",
    "last = n_tune - n_burn - np.sum(n_window)\n",
    "if last < n_window[-1]:\n",
    "    n_window[-1] += last\n",
    "else:\n",
    "    n_window = np.append(n_window, last)\n",
    "n_window = n_window.astype(int)\n",
    "print(n_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymc3.step_methods.hmc.quadpotential import QuadPotentialFull\n",
    "\n",
    "def get_step_for_trace(trace=None, model=None,\n",
    "                       regular_window=5, regular_variance=1e-3,\n",
    "                       **kwargs):\n",
    "    model = pm.modelcontext(model)\n",
    "    \n",
    "    # If not given, use the trivial metric\n",
    "    if trace is None:\n",
    "        potential = QuadPotentialFull(np.eye(model.ndim))\n",
    "        return pm.NUTS(potential=potential, **kwargs)\n",
    "        \n",
    "    # Loop over samples and convert to the relevant parameter space;\n",
    "    # I'm sure that there's an easier way to do this, but I don't know\n",
    "    # how to make something work in general...\n",
    "    samples = np.empty((len(trace) * trace.nchains, model.ndim))\n",
    "    i = 0\n",
    "    for chain in trace._straces.values():\n",
    "        for p in chain:\n",
    "            samples[i] = model.bijection.map(p)\n",
    "            i += 1\n",
    "    \n",
    "    # Compute the sample covariance\n",
    "    cov = np.cov(samples, rowvar=0)\n",
    "    \n",
    "    # Stan uses a regularized estimator for the covariance matrix to\n",
    "    # be less sensitive to numerical issues for large parameter spaces.\n",
    "    # In the test case for this blog post, this isn't necessary and it\n",
    "    # actually makes the performance worse so I'll disable it, but I\n",
    "    # wanted to include the implementation here for completeness\n",
    "    N = len(samples)\n",
    "    cov = cov * N / (N + regular_window)\n",
    "    cov[np.diag_indices_from(cov)] += \\\n",
    "        regular_variance * regular_window / (N + regular_window)\n",
    "    \n",
    "    # Use the sample covariance as the inverse metric\n",
    "    potential = QuadPotentialFull(cov)\n",
    "    return pm.NUTS(potential=potential, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    start = soln\n",
    "    burnin_trace = None\n",
    "    for steps in n_window:\n",
    "        step = get_step_for_trace(burnin_trace)\n",
    "        burnin_trace = pm.sample(\n",
    "            start=start, tune=steps, draws=2, step=step,\n",
    "            compute_convergence_checks=False, discard_tuned_samples=False)\n",
    "        start = [t[-1] for t in burnin_trace._straces.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(burnin_trace, varnames=[\"logw0\", \"logS0\", \"logs2\", \"logr\", \"b\", \"t0\", \"logporb\", \"mean\", \"rho\", \"q\", \"ecc\", \"w\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    step = get_step_for_trace(burnin_trace)\n",
    "    trace = pm.sample(draws=500, tune=n_burn, step=step, start=start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(trace, varnames=[\"logS0\", \"logw0\", \"logs2\", \"logr\", \"b\", \"t0\", \"logporb\", \"mean\", \"rho\", \"q\", \"ecc\", \"w\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import corner\n",
    "df = pm.trace_to_dataframe(trace, varnames=[\"mean\", \"logS0\", \"logw0\"])\n",
    "corner.corner(df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, y_fit, \".k\")\n",
    "\n",
    "for i in np.random.randint(len(trace) * trace.nchains, size=25):\n",
    "    plt.plot(x, trace[\"transit\"][i], color=\"C0\", alpha=0.5)\n",
    "    plt.plot(x, trace[\"gp\"][i], color=\"C1\", alpha=0.5)\n",
    "plt.xlim(5.8, 7.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
